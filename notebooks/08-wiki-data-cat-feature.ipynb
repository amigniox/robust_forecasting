{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add feature\n",
    "\n",
    "#### This notebook demonstrates that how to segment any given dataset based on the types of workload included in it.\n",
    "#### This notebook also includes examples of different time series types, and how to inteprate the *characteristic scores*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important window definition\n",
    "prediction_length = 48\n",
    "context_length = 72\n",
    "day = 24\n",
    "week = 148\n",
    "month = 720\n",
    "year = 8760\n",
    "\n",
    "freq = 'H'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Time Series data and corresponding wiki project name\n",
    "def get_ts_and_name(data_location,label_location,freq):\n",
    "    df_ts = pd.read_json(data_location, lines=True)\n",
    "    num_pt = min(len(df_ts.iloc[1, 1]), 100000)\n",
    "    print('use first ', num_pt, ' points in a time series')\n",
    "    num_ts = len(df_ts)\n",
    "\n",
    "    time_series_wiki = []\n",
    "    for k in range(num_ts):\n",
    "        t0 = df_ts.iloc[k, 0]\n",
    "        data = df_ts.iloc[k, 1][:num_pt]\n",
    "        index = pd.DatetimeIndex(start=t0, freq=freq, periods=num_pt)\n",
    "        time_series_wiki.append(pd.Series(data=data, index=index))\n",
    "        \n",
    "    with open(label_location) as f:\n",
    "        wp_list = f.read().splitlines()  \n",
    "        \n",
    "    return time_series_wiki, wp_list\n",
    "\n",
    "# get the Time Series data and corresponding wiki project name\n",
    "def get_ts(data_location,freq):\n",
    "    df_ts = pd.read_json(data_location, lines=True)\n",
    "    num_pt = min(len(df_ts.iloc[1, 1]), 100000)\n",
    "    print('use first ', num_pt, ' points in a time series')\n",
    "    num_ts = len(df_ts)\n",
    "\n",
    "    time_series_wiki = []\n",
    "    for k in range(num_ts):\n",
    "        t0 = df_ts.iloc[k, 0]\n",
    "        data = df_ts.iloc[k, 1][:num_pt]\n",
    "        index = pd.DatetimeIndex(start=t0, freq=freq, periods=num_pt)\n",
    "        time_series_wiki.append(pd.Series(data=data, index=index))       \n",
    "    return time_series_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_location = 'wp_full-20180101-20190101_get.txt'    \n",
    "# data_location = 'test_1year.json'\n",
    "# \n",
    "\n",
    "# time_series_wiki = get_ts(data_location,freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use first  17544  points in a time series\n"
     ]
    }
   ],
   "source": [
    "input_file = 'train_nan.json'\n",
    "output_file = \"train_nan_cat1.json\"\n",
    "\n",
    "time_series_wiki_1 = get_ts(input_file,freq)\n",
    "raw_jsons = []\n",
    "with open(input_file) as f:\n",
    "    for line in f:\n",
    "        raw_jsons.append(json.loads(line))\n",
    "# print(raw_jsons[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8311"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_wiki_1[322].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_0 = time_series_wiki_1[322].replace(to_replace=np.nan, value=0, inplace = False)\n",
    "tm_0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_series_wiki_1[322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_series_wiki_1[322].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with s3filesystem.open(os.path.join(S3_DATA_PATH, \"test\", \"train_data.json\"), 'wb') as fp:\n",
    "#     for ts in timeseries_training:\n",
    "#         fp.write(series_to_jsonline(ts).encode(encoding))\n",
    "#         fp.write('\\n'.encode(encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The time series characterization tool based on discrete Fourier transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete Fourier transform with FFT\n",
    "def discrete_ft(x,window):\n",
    "    # important variables are written explicitly\n",
    "    y = x.values # signal\n",
    "\n",
    "    Fs = 1 # sampling rate, in our case let's use 1 Hour^-1\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "\n",
    "    # we only keep the positive frequency up to the Nyquist = 1/2*Fs\n",
    "    cycle = frq[range(1,int(n/2))] * window # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(1, int(n/2))] # again, spectrum corrresponding to the positive half\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize = (10,5))\n",
    "    ax[0].plot(x)\n",
    "    ax[0].set_xlabel('Time')\n",
    "    ax[0].set_ylabel('network traffic')\n",
    "    ax[1].plot(cycle,abs(Y),'r') # plotting the spectrum\n",
    "    ax[1].set_xlabel('cycles per '+str(window)+' hours')\n",
    "    ax[1].set_ylabel('network frequency spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series characterization with FFT\n",
    "import heapq\n",
    "def characterize_ts(ts, window):\n",
    "    y = ts.values  # signal\n",
    "    Fs = 1  # sampling rate, in our case let's use 1 Hour^-1\n",
    "    n = len(y)  # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n / Fs\n",
    "    frq = k / T  # two sides frequency range\n",
    "    # We only keep the positive frequency up to the Nyquist = 1/(2*dT), dT = sampling interval.\n",
    "    cycle = frq[range(1, int(n / 2))] * window  # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y) / n  # fft computing and normalization\n",
    "    Y = Y[range(1, int(n / 2))]  # again, spectrum corrresponding to the positive half\n",
    "    yabs = np.abs(Y)\n",
    "\n",
    "    # Locate the largest 15 peaks, use them to characterise the time series.\n",
    "    indx = heapq.nlargest(15, range(len(yabs)), yabs.__getitem__)\n",
    "    amp = heapq.nlargest(15, yabs)\n",
    "\n",
    "    mean = yabs.mean()\n",
    "    std = yabs.std()\n",
    "    cyc_hday = 2.0\n",
    "    cyc_day = cyc_hday / 2.0\n",
    "    cyc_week = cyc_day / 7.0\n",
    "    cyc_month = cyc_day / 30.0\n",
    "\n",
    "    comp = lambda a, b: np.abs(a / b - 1) < 0.05\n",
    "    ts_type = ['trend', 'hDay', 'Day', 'Week', 'Month', 'DayImpulse', 'spike']\n",
    "    report_list = [0] * 8\n",
    "    for counter, value in enumerate(indx):\n",
    "        # Here we define a peak in frequency domain.\n",
    "        if amp[counter] > (mean + 3 * std):\n",
    "            amp_norm = (amp[counter] - mean) / std\n",
    "            if cycle[value] < 0.01:\n",
    "                # Trend (increasing, decreasing, gaussian pulse).\n",
    "                report_list[0] = max(amp_norm, report_list[0])\n",
    "            elif comp(cycle[value], cyc_hday):\n",
    "                report_list[1] = max(amp_norm, report_list[1])\n",
    "            elif comp(cycle[value], cyc_day):\n",
    "                report_list[2] = max(amp_norm, report_list[2])\n",
    "            elif comp(cycle[value], cyc_week):\n",
    "                report_list[3] = max(amp_norm, report_list[3])\n",
    "            elif comp(cycle[value], cyc_month):\n",
    "                report_list[4] = max(amp_norm, report_list[4])\n",
    "\n",
    "    if sum(report_list[:5]) > 0:\n",
    "        index = report_list[:5].index(max(report_list[:5]))\n",
    "        report_list[5] = ts_type[index]\n",
    "    else:\n",
    "        report_list[5] = ts_type[-1]\n",
    "\n",
    "    # Add a subcategory: a special day seasonality that has a periodic impulse shape.\n",
    "    if report_list[5] == 'hDay' or report_list[5] == 'Day':\n",
    "        harmonic = set(range(12))\n",
    "        all_peak = set()\n",
    "        for counter, value in enumerate(indx):\n",
    "            if amp[counter] > (mean + 3 * std):\n",
    "                all_peak.add(int(round(cycle[value])))\n",
    "        if len(harmonic.intersection(all_peak)) > 10:\n",
    "            report_list[5] = ts_type[-2]\n",
    "\n",
    "    report_list[-2] = y.mean()\n",
    "    report_list[-1] = y.std()\n",
    "    return report_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_0 = time_series_wiki_1[200].replace(to_replace=np.nan, value=0, inplace = False)\n",
    "# ans1 = characterize_ts(ts_0,day)\n",
    "# ans2 = characterize_ts(ts_0[-year:],day)\n",
    "# print(ans1)\n",
    "# print(ans2)\n",
    "# discrete_ft(ts_0,day)\n",
    "# discrete_ft(ts_0[-year:],day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the report list to Pandas dataframe for easier speculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to new JSON lines with cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_obj(ts, cat=None):\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": list(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    return obj\n",
    "\n",
    "def series_to_jsonline(ts, cat=None):\n",
    "    return json.dumps(series_to_obj(ts, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_feature(score, boundary_12, bounadry_23):\n",
    "    # Default category assignment.\n",
    "    cat = 0 \n",
    "    if score > 0:\n",
    "        if score < boundary_12:\n",
    "            cat = 1\n",
    "        elif score < bounadry_23:\n",
    "            cat = 2\n",
    "        else:\n",
    "            cat = 3\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ts_cat(time_series, output_file):\n",
    "    encoding = 'utf-8'\n",
    "    with open(output_file, 'wb') as fp:\n",
    "        for i, ts in enumerate(time_series):\n",
    "            ts_0val = ts.replace(to_replace=np.nan, value=0, inplace = False)\n",
    "            character_list = characterize_ts(ts_0val[-year:],day)\n",
    "            cat = [0] * 3\n",
    "            # Catagory for Trend characteristic\n",
    "            cat[0] = cat_feature(character_list[0], 10, 20)\n",
    "            # Category for HalfDay characteristic\n",
    "            cat[1] = cat_feature(character_list[1], 10, 20)\n",
    "            # Category for Day characteristic\n",
    "            cat[2] = cat_feature(character_list[2], 20, 40)\n",
    "            raw_jsons[i]['cat'] = cat\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        outfile.write('\\n'.join(json.dumps(i) for i in raw_jsons) + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ts_cat_1(time_series, output_file):\n",
    "    encoding = 'utf-8'\n",
    "    with open(output_file, 'wb') as fp:\n",
    "        for i, ts in enumerate(time_series):\n",
    "            ts_0val = ts.replace(to_replace=np.nan, value=0, inplace = False)\n",
    "            character_list = characterize_ts(ts_0val[-year:],day)\n",
    "            # Catagory for scale\n",
    "            cat = [0]\n",
    "            cat[0] = cat_feature(character_list[-2], 100, 1000) -1\n",
    "            raw_jsons[i]['cat'] = cat\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        outfile.write('\\n'.join(json.dumps(i) for i in raw_jsons) + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_ts_cat(time_series_wiki_1, output_file)\n",
    "save_ts_cat_1(time_series_wiki_1, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>start</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[5, 8, 9, 4, 13, 17, 18, 4, 7, 4, 23, 7, 5, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[1, None, 1, None, None, 1, 3, 2, 2, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[None, 1, None, None, None, 1, 1, 1, None, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[30, 39, 47, 26, 35, 37, 128, 91, 135, 114, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[36, 45, 81, 48, 31, 57, 251, 188, 204, 276, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[1356, 1130, 1069, 1013, 945, 1674, 1919, 1973...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[4, 4, 4, 7, 21, 3, 8, 9, 5, 5, 4, 4, 5, 6, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[14, 13, 13, 17, 6, 68, 27, 22, 27, 22, 45, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[5, 8, 5, 8, 3, 3, 23, 11, 22, 26, 10, 8, 11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[8, 22, 15, 10, 14, 20, 97, 48, 56, 49, 61, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[304, 332, 306, 254, 262, 289, 804, 707, 1013,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[None, None, None, 1, None, None, None, None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[1, 2, None, 1, None, None, None, 1, 1, None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[2, 1, 2, 1, 1, 1, 3, 3, None, 1, 3, 2, None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[147, 211, 172, 192, 265, 342, 523, 472, 744, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0]</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>[2, 5, 5, 4, 3, 6, 6, 10, 5, 6, 4, 4, 5, 5, 2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat                start  \\\n",
       "0   [0]  2016-01-01 00:00:00   \n",
       "1   [0]  2016-01-01 00:00:00   \n",
       "2   [0]  2016-01-01 00:00:00   \n",
       "3   [1]  2016-01-01 00:00:00   \n",
       "4   [0]  2016-01-01 00:00:00   \n",
       "5   [1]  2016-01-01 00:00:00   \n",
       "6   [0]  2016-01-01 00:00:00   \n",
       "7   [2]  2016-01-01 00:00:00   \n",
       "8   [0]  2016-01-01 00:00:00   \n",
       "9   [0]  2016-01-01 00:00:00   \n",
       "10  [0]  2016-01-01 00:00:00   \n",
       "11  [0]  2016-01-01 00:00:00   \n",
       "12  [0]  2016-01-01 00:00:00   \n",
       "13  [0]  2016-01-01 00:00:00   \n",
       "14  [1]  2016-01-01 00:00:00   \n",
       "15  [0]  2016-01-01 00:00:00   \n",
       "16  [0]  2016-01-01 00:00:00   \n",
       "17  [0]  2016-01-01 00:00:00   \n",
       "18  [1]  2016-01-01 00:00:00   \n",
       "19  [0]  2016-01-01 00:00:00   \n",
       "\n",
       "                                               target  \n",
       "0   [5, 8, 9, 4, 13, 17, 18, 4, 7, 4, 23, 7, 5, 3,...  \n",
       "1   [1, None, 1, None, None, 1, 3, 2, 2, None, Non...  \n",
       "2   [None, 1, None, None, None, 1, 1, 1, None, 1, ...  \n",
       "3   [30, 39, 47, 26, 35, 37, 128, 91, 135, 114, 17...  \n",
       "4   [None, None, None, None, None, None, None, Non...  \n",
       "5   [36, 45, 81, 48, 31, 57, 251, 188, 204, 276, 4...  \n",
       "6   [None, None, None, None, None, None, None, Non...  \n",
       "7   [1356, 1130, 1069, 1013, 945, 1674, 1919, 1973...  \n",
       "8   [4, 4, 4, 7, 21, 3, 8, 9, 5, 5, 4, 4, 5, 6, 6,...  \n",
       "9   [14, 13, 13, 17, 6, 68, 27, 22, 27, 22, 45, 19...  \n",
       "10  [5, 8, 5, 8, 3, 3, 23, 11, 22, 26, 10, 8, 11, ...  \n",
       "11  [8, 22, 15, 10, 14, 20, 97, 48, 56, 49, 61, 36...  \n",
       "12  [None, None, None, None, None, None, None, Non...  \n",
       "13  [None, None, None, None, None, None, None, Non...  \n",
       "14  [304, 332, 306, 254, 262, 289, 804, 707, 1013,...  \n",
       "15  [None, None, None, 1, None, None, None, None, ...  \n",
       "16  [1, 2, None, 1, None, None, None, 1, 1, None, ...  \n",
       "17  [2, 1, 2, 1, 1, 1, 3, 3, None, 1, 3, 2, None, ...  \n",
       "18  [147, 211, 172, 192, 265, 342, 523, 472, 744, ...  \n",
       "19  [2, 5, 5, 4, 3, 6, 6, 10, 5, 6, 4, 4, 5, 5, 2,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ts_wiki_2 = get_ts(output_file, freq)\n",
    "test_df = pd.read_json(output_file, lines=True)\n",
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
