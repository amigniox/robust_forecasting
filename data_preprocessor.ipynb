{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import s3fs\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "!conda install -y s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface of this file\n",
    "# IN: wiki item list, time range\n",
    "# OUT: json lines on S3 (used for training, test or prediction)\n",
    "\n",
    "all_data = []\n",
    "project_list = []\n",
    "delta = datetime.timedelta(days=199)\n",
    "hour = datetime.timedelta(hours=1)\n",
    "zero = datetime.timedelta(hours=0)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(start, end, wiki_list, s3_json, access, agent):\n",
    "    s3filesystem = s3fs.S3FileSystem()\n",
    "    start_date = datetime.datetime.strptime(start, '%Y%m%d')\n",
    "    end_date = datetime.datetime.strptime(end, '%Y%m%d')\n",
    "    if (end_date - start_date).days < 0:\n",
    "        raise Exception('start date should NOT after end date')\n",
    "\n",
    "    expected_size = ((end_date - start_date).days + 1) * 24\n",
    "\n",
    "    # provide wiki-project list here!\n",
    "    with open(wiki_list) as f:\n",
    "        projects = f.read().splitlines()\n",
    "\n",
    "    for item in projects:\n",
    "        data, count_null = get_single_views(item, start_date, end_date, access, agent)\n",
    "        if len(data['target']) == expected_size and count_null / len(data['target']) < 0.2:\n",
    "            all_data.append(data)\n",
    "            project_list.append(item)\n",
    "\n",
    "    # convert all items to JSON and write to a file\n",
    "    print('saving data')\n",
    "    with open(wiki_list[:-4] + '-' + str(start) + '-' + str(end) + '-get.txt', 'w') as f:\n",
    "        for item in project_list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    with s3filesystem.open(s3_json, 'w') as outfile:\n",
    "        outfile.write('\\n'.join(json.dumps(i) for i in all_data) + '\\n')\n",
    "    all_data.clear()\n",
    "    project_list.clear()\n",
    "\n",
    "\n",
    "def get_single_views(item, start_date, end_date, access, agent):\n",
    "    base_url = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/' \\\n",
    "               + item \\\n",
    "               + '/' + access + '/' + agent + '/hourly/'\n",
    "    # dict is used to save JSON of each domain\n",
    "    data = dict()\n",
    "    data['start'] = start_date.strftime('%Y-%m-%d') + ' 00:00:00'\n",
    "    data['target'] = []\n",
    "    count_null = 0\n",
    "\n",
    "    while start_date <= end_date:\n",
    "        if start_date + delta <= end_date:\n",
    "            final_url = base_url + start_date.strftime('%Y%m%d') + '00/' \\\n",
    "                        + (start_date + delta).strftime('%Y%m%d') + '23'\n",
    "            end_check = start_date + delta + 23 * hour\n",
    "        else:\n",
    "            final_url = base_url + start_date.strftime('%Y%m%d') + '00/' \\\n",
    "                        + end_date.strftime('%Y%m%d') + '23'\n",
    "            end_check = end_date + 23 * hour\n",
    "        # make a API request here!!!\n",
    "        response = requests.get(final_url)\n",
    "        time.sleep(0.05)\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(\"<-----Error---->: \" + final_url + str(e))\n",
    "            break\n",
    "        print('<-----OK----->' + final_url)  # debug\n",
    "        output = response.json()\n",
    "        print('processed data points: ' + str(len(output['items'])))  # debug\n",
    "        temp = start_date - hour\n",
    "        for i in output['items']:\n",
    "            curr = datetime.datetime.strptime(i['timestamp'], '%Y%m%d%H')\n",
    "            while curr - temp > hour:\n",
    "                data['target'].append(None)\n",
    "                count_null += 1\n",
    "                temp += hour\n",
    "            data['target'].append(i['views'])\n",
    "            temp = curr\n",
    "\n",
    "        while (end_check - temp) > zero:\n",
    "            data['target'].append(None)\n",
    "            count_null += 1\n",
    "            temp += hour\n",
    "\n",
    "        start_date += datetime.timedelta(days=200)\n",
    "\n",
    "    return data, count_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage example\n",
    "save_json('20160101', '20160201', 'wp.txt', 'sagemaker-deepar20190120/sagemaker/wiki-test-deepar/data/playground/test.json', 'all-access', 'all-agents')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
