{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor\n",
    "\n",
    "What you need:\n",
    "Specify the Endpoint of the deployed model and test data channel.\n",
    "\n",
    "What it does:\n",
    "Query the endpoint and get inference. Further analysis can be added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface of this file\n",
    "# Input: S3 path of json lines\n",
    "# Output: original time series list and predicted time series list\n",
    "\n",
    "input_path = \"s3://sagemaker-deepar20190120/sagemaker/wiki-test-deepar/data/test_subset/test.json\"\n",
    "freq = 'H'\n",
    "prediction_length = 48\n",
    "context_length = 118\n",
    "ep = \"DEMO-deepar-2019-02-07-03-16-16-206\"\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "\n",
    "    def set_prediction_parameters(self, freq, prediction_length):\n",
    "        \"\"\"Set the time frequency and prediction length parameters. This method **must** be called\n",
    "        before being able to use `predict`.\n",
    "\n",
    "        Parameters:\n",
    "        freq -- string indicating the time frequency\n",
    "        prediction_length -- integer, number of predicted time points\n",
    "\n",
    "        Return value: none.\n",
    "        \"\"\"\n",
    "        self.freq = freq\n",
    "        self.prediction_length = prediction_length\n",
    "\n",
    "    def predict(self, ts, cat=None, encoding=\"utf-8\", num_samples=100, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        Parameters:\n",
    "        ts -- list of `pandas.Series` objects, the time series to predict\n",
    "        cat -- list of integers (default: None)\n",
    "        encoding -- string, encoding to use for the request (default: \"utf-8\")\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_times = [x.index[-1] + 1 for x in ts]\n",
    "        req = self.__encode_request(ts, cat, encoding, num_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, prediction_times, encoding)\n",
    "\n",
    "    def __encode_request(self, ts, cat, encoding, num_samples, quantiles):\n",
    "        instances = [series_to_obj(ts[k], cat[k] if cat else None) for k in range(len(ts))]\n",
    "        configuration = {\"num_samples\": num_samples, \"output_types\": [\"quantiles\"], \"quantiles\": quantiles}\n",
    "        http_request_data = {\"instances\": instances, \"configuration\": configuration}\n",
    "        return json.dumps(http_request_data).encode(encoding)\n",
    "\n",
    "    def __decode_response(self, response, prediction_times, encoding):\n",
    "        response_data = json.loads(response.decode(encoding))\n",
    "        list_of_df = []\n",
    "        for k in range(len(prediction_times)):\n",
    "            prediction_index = pd.DatetimeIndex(start=prediction_times[k], freq=self.freq,\n",
    "                                                periods=self.prediction_length)\n",
    "            list_of_df.append(pd.DataFrame(data=response_data['predictions'][k]['quantiles'], index=prediction_index))\n",
    "        return list_of_df\n",
    "\n",
    "\n",
    "# helper func\n",
    "def series_to_obj(ts, cat=None):\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": list(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    return obj\n",
    "\n",
    "\n",
    "# helper func\n",
    "def series_to_jsonline(ts, cat=None):\n",
    "    return json.dumps(series_to_obj(ts, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DeepARPredictor(\n",
    "    endpoint=ep,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "\n",
    "\n",
    "predictor.set_prediction_parameters(freq, prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: json lines, string or file path or S3 url\n",
    "# Output: list of original time series, list of predicted DATA FRAME\n",
    "def get_predictions(input_path):\n",
    "    df_ts = pd.read_json(input_path, lines=True)\n",
    "    num_pt = len(df_ts.iloc[1, 1])\n",
    "    num_ts = len(df_ts)\n",
    "    ts_orig = []\n",
    "    ts_to_pred = []\n",
    "    for k in range(num_ts):\n",
    "        t0 = df_ts.iloc[k, 0]\n",
    "        data = df_ts.iloc[k, 1]\n",
    "        index = pd.DatetimeIndex(start=t0, freq=freq, periods=num_pt)\n",
    "        ts = pd.Series(data=data, index=index)\n",
    "        ts_0val = ts.replace({np.nan: 0}, inplace = False)\n",
    "        # Only replace missing values to 0 when doing plotting, NOT in prediction!\n",
    "        ts_orig.append(ts_0val)\n",
    "        # Predictor only recognizes null literal as missing values, not np.nan.\n",
    "        ts.replace({np.nan: None}, inplace = True)\n",
    "        ts_to_pred.append(ts[:-prediction_length])\n",
    "        \n",
    "    ts_predicted = []\n",
    "    for series in ts_to_pred:\n",
    "        ts_predicted.append(predictor.predict([series]))\n",
    "        time.sleep(0.01)\n",
    "    return ts_orig, ts_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big call here!!!\n",
    "time_series_wiki, list_of_wiki_pred = get_predictions(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Amazing Analysis and Plot Blow (not really)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
